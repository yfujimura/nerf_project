{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1699aff-8386-46bf-bd12-fbdc39973cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5fcc474-b749-4426-a97b-93db570a16f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import SyntheticNerfDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7702e99-0844-4ed4-9dda-8d7ee891c866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [00:00<00:00, 289.39it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SyntheticNerfDataset(\n",
    "    datadir = \"/root/workdir/dataset/nerf_synthetic/chair\",\n",
    "    split=\"train\",\n",
    "    batch_size=8129\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e357bf0c-5794-4ef7-b135-55873715c7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dloader_random(_):\n",
    "    seed = torch.initial_seed() % 2**32  # worker-specific seed initialized by pytorch\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "train_dataset.reset_iter()\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, num_workers=4, prefetch_factor=4, pin_memory=True,\n",
    "    batch_size=None, worker_init_fn=init_dloader_random)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30d2a998-a4bd-4232-b559-65661d5d8d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "458ce80d-a4d1-47f5-b678-adfc1dfbeee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs2 = np.copy(train_dataset.imgs)\n",
    "rays_d2 = np.copy(train_dataset.rays_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2082c87-7026-409b-b443-ca0e8527f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/root/imgs2\", imgs2)\n",
    "np.save(\"/root/rays_d2\", rays_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff6bb65-2f93-4f57-8c4d-34f4f3345640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rays_d1 = np.load(\"/root/imgs1.npy\")\n",
    "rays_d2 = np.load(\"/root/imgs2.npy\")\n",
    "np.sum(rays_d1 - rays_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b78f7290-3ca3-4269-90b1-928b6c2dcea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(imgs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39b14965-79bf-4576-a7c6-833349b5710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "poses_bounds = np.load(\"/root/workdir/dataset/nerf_llff_data/fern/poses_bounds.npy\")\n",
    "near_fars = poses_bounds[:, -2:]  # (N_images, 2)\n",
    "poses = poses_bounds[:, :15].reshape(-1, 3, 5)  # (N_images, 3, 5)\n",
    "H, W, focal = poses[0, :, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30f2bdbf-5c48-4664-924e-20ebd40b3098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02242252,  0.98963074, -0.141874  , -3.67917907],\n",
       "       [ 0.99912101, -0.02720908, -0.0318884 , -1.60379162],\n",
       "       [-0.035418  , -0.14103427, -0.98937096, -0.27680206]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses[:, :, :4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15cef746-5896-4ade-bdfb-e6cf03d675f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.24225156e-02,  9.89630739e-01, -1.41873998e-01,\n",
       "        -3.67917907e+00,  3.02400000e+03],\n",
       "       [ 9.99121012e-01, -2.72090794e-02, -3.18884009e-02,\n",
       "        -1.60379162e+00,  4.03200000e+03],\n",
       "       [-3.54180026e-02, -1.41034274e-01, -9.89370961e-01,\n",
       "        -2.76802064e-01,  3.26052633e+03]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0cd0b9c-9373-4ea7-8b1b-ba0b11209e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b5361f-5a91-4ea6-9c65-874c83a306fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"configs/0710.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24956e05-f1b8-41a3-9ca2-0e879db5d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = importlib.util.spec_from_file_location(os.path.basename(config_path), config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88d74046-4491-4c5c-be0c-35844a8ee3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleSpec(name='0710.py', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7fce203e8910>, origin='configs/0710.py')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89c751a8-2156-4623-8420-cda63f640d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = importlib.util.module_from_spec(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "152d9659-1a5e-439c-9db3-4036e3e7250c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f50127c4-cc4c-40b6-8fdb-d9eac5d41c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec.loader.exec_module(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66e44d45-2318-4b59-8b69-d08db3d1ed7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'expname': '0710_darf',\n",
       " 'logdir': './output/0710',\n",
       " 'device': 'cuda:0',\n",
       " 'data_downsample': 1.0,\n",
       " 'data_dirs': ['./data/scannet/scene0710_00'],\n",
       " 'checkpoint': './output/0710/0710_darf/model_25000.pth',\n",
       " 'contract': False,\n",
       " 'ndc': False,\n",
       " 'load_stereo': False,\n",
       " 'stereo_loss_weight': 1.0,\n",
       " 'stereo_dir': 'darf',\n",
       " 'blength': 0.05,\n",
       " 'near': 0.1,\n",
       " 'far': 4.04,\n",
       " 'radius': 1.5,\n",
       " 'fewshot': None,\n",
       " 'patch_rendering': 64,\n",
       " 'DPT_adaptor': True,\n",
       " 'novel_detach': True,\n",
       " 'adaptor_weight': 0.1,\n",
       " 'adaptor_lr': 0.0001,\n",
       " 'depth_loss': 'l1_ranking',\n",
       " 'depth_loss_range': [0, 25001],\n",
       " 'warp': True,\n",
       " 'depth_weight': 0.1,\n",
       " 'ranking_step': 1000,\n",
       " 'fake_img': '_novel_test',\n",
       " 'stride': 3,\n",
       " 'novel_patch_size': 128,\n",
       " 'dpt_weight_path': '.',\n",
       " 'novel_depth_loss': 0.01,\n",
       " 'novel_depth_loss_function': 'scale_shift',\n",
       " 'novel_depth_loss_range': [5001, 25000],\n",
       " 'convention': 'XYZ',\n",
       " 'num_steps': 25001,\n",
       " 'batch_size': 4096,\n",
       " 'scheduler_type': 'warmup_cosine',\n",
       " 'optim_type': 'adam',\n",
       " 'lr': 0.01,\n",
       " 'plane_tv_weight': 0.01,\n",
       " 'plane_tv_weight_proposal_net': 0.0001,\n",
       " 'histogram_loss_weight': 1.0,\n",
       " 'distortion_loss_weight': 0.001,\n",
       " 'save_every': 5000,\n",
       " 'valid_every': 5000,\n",
       " 'save_outputs': True,\n",
       " 'train_fp16': True,\n",
       " 'single_jitter': False,\n",
       " 'num_samples': 48,\n",
       " 'num_proposal_samples': [256, 128],\n",
       " 'num_proposal_iterations': 2,\n",
       " 'use_same_proposal_network': False,\n",
       " 'use_proposal_weight_anneal': True,\n",
       " 'proposal_net_args_list': [{'num_input_coords': 3,\n",
       "   'num_output_coords': 8,\n",
       "   'resolution': [64, 64, 64]},\n",
       "  {'num_input_coords': 3,\n",
       "   'num_output_coords': 8,\n",
       "   'resolution': [128, 128, 128]}],\n",
       " 'multiscale_res': [1, 2, 4, 8],\n",
       " 'density_activation': 'trunc_exp',\n",
       " 'concat_features_across_scales': True,\n",
       " 'linear_decoder': False,\n",
       " 'grid_config': [{'grid_dimensions': 2,\n",
       "   'input_coordinate_dim': 3,\n",
       "   'output_coordinate_dim': 32,\n",
       "   'resolution': [64, 64, 64]}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3898b515-6e28-46c1-b8b0-8caf50ad87e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4696c0c7-6890-4e19-a991-79dd4e22bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/root/workdir/dataset/nerf_synthetic/chair/transforms_test.json\", \"r\") as f:\n",
    "    meta = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81f92b32-5bb1-481d-b2fd-62e9d5b68f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/root/workdir/dataset/nerf_synthetic/chair\"\n",
    "split = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1050940-33f0-4539-ba0d-4d7ace12d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = meta[\"frames\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3049292f-6dd6-4c05-af4a-73f6e3720fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = []\n",
    "imgs = []\n",
    "for frame in frames:\n",
    "    imgs.append(Image.open(os.path.join(data_dir, split, os.path.basename(frame[\"file_path\"]+\".png\"))))\n",
    "    poses.append(frame[\"transform_matrix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82422150-cb38-4cda-acec-774a22a009af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.9980267286300659,\n",
       "  0.04609514772891998,\n",
       "  -0.042636688798666,\n",
       "  -0.17187398672103882],\n",
       " [-0.06279052048921585,\n",
       "  -0.7326614260673523,\n",
       "  0.6776907444000244,\n",
       "  2.731858730316162],\n",
       " [-3.7252898543727042e-09,\n",
       "  0.6790306568145752,\n",
       "  0.7341099381446838,\n",
       "  2.959291696548462],\n",
       " [0.0, 0.0, 0.0, 1.0]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ed650e9-edf3-41d4-93cb-85a90e428856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6911112070083618"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[\"camera_angle_x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f184b46-25ba-4e46-a53d-8bae5b828a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d95a01ce-34a4-4617-b60b-e523cf1da9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor(np.zeros((100,100,3)))\n",
    "x2 = torch.tensor(np.zeros((100,100,3)))\n",
    "x3 = torch.stack((x1,x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ffa9e72-de3f-4cd7-8f20-f0a87c2db19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 100, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f56347-a23d-40b1-bdb2-5b5d89edcd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trimip",
   "language": "python",
   "name": "trimip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
